{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer for: unsloth/gemma-3-1b-it...\n",
      "Tokenizer loaded successfully using AutoTokenizer.\n",
      "\n",
      "Loading dataset processor for: finqa...\n",
      "Dataset processor loaded successfully.\n",
      "\n",
      "--- Analyzing split: train ---\n",
      "Number of examples: 6251\n",
      "Tokenizing example 1500/6251 in train...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                \n",
      "Input Token Statistics:\n",
      "  Total input tokens in split: 2574022\n",
      "  Min input tokens per example: 134\n",
      "  Max input tokens per example: 1391\n",
      "  Mean input tokens per example: 411.77763557830747\n",
      "  Unique input tokens (diversity in this split): 10054\n",
      "\n",
      "Output Token Statistics:\n",
      "  Total output tokens in split: 33861\n",
      "  Min output tokens per example: 2\n",
      "  Max output tokens per example: 116\n",
      "  Mean output tokens per example: 5.416893297072469\n",
      "  Unique output tokens (diversity in this split): 172\n",
      "\n",
      "--- 5 Random Examples from 'train' Split ---\n",
      "\n",
      "--- Example 1/5 (Original Index: 2422) ---\n",
      "Input Prompt (Formatted for Model):\n",
      "<bos><start_of_turn>user\n",
      "You are a helpful AI assistant that answers questions based on provided financial data.\n",
      "\n",
      "net sales increased by what percent from 2005 to 2006?\n",
      "results of operations year ended december 31 , 2006 compared to year ended december 31 , 2005 the historical results of operations of pca for the years ended december 31 , 2006 and 2005 are set forth below : for the year ended december 31 , ( in millions ) 2006 2005 change .\n",
      "( in millions )\tfor the year ended december 31 , 2006\tfor the year ended december 31 , 2005\tchange\n",
      "net sales\t$ 2187.1\t$ 1993.7\t$ 193.4\n",
      "income from operations\t$ 225.9\t$ 116.1\t$ 109.8\n",
      "interest expense net\t-31.2 ( 31.2 )\t-28.1 ( 28.1 )\t-3.1 ( 3.1 )\n",
      "income before taxes\t194.7\t88.0\t106.7\n",
      "provision for income taxes\t-69.7 ( 69.7 )\t-35.4 ( 35.4 )\t-34.3 ( 34.3 )\n",
      "net income\t$ 125.0\t$ 52.6\t$ 72.4\n",
      "net sales net sales increased by $ 193.4 million , or 9.7% ( 9.7 % ) , for the year ended december 31 , 2006 from the year ended december 31 , 2005 .\n",
      "net sales increased primarily due to increased sales prices and volumes of corrugated products and containerboard compared to 2005 .\n",
      "total corrugated products volume sold increased 0.4% ( 0.4 % ) to 31.3 billion square feet in 2006 compared to 31.2 billion square feet in 2005 .<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n",
      "\n",
      "Output Answer (Ground Truth):\n",
      "9.7%\n",
      "\n",
      "--- Example 2/5 (Original Index: 3181) ---\n",
      "Input Prompt (Formatted for Model):\n",
      "<bos><start_of_turn>user\n",
      "You are a helpful AI assistant that answers questions based on provided financial data.\n",
      "\n",
      "in 2007 what was the percentage change in the account balance of unrecognized tax benefits based on the reconciliation at december 31 .\n",
      "determined that it will primarily be subject to the ietu in future periods , and as such it has recorded tax expense of approximately $ 20 million in 2007 for the deferred tax effects of the new ietu system .\n",
      "as of december 31 , 2007 , the company had us federal net operating loss carryforwards of approximately $ 206 million which will begin to expire in 2023 .\n",
      "of this amount , $ 47 million relates to the pre-acquisition period and is subject to limitation .\n",
      "\tyear ended december 31 2007 ( in $ millions )\n",
      "balance as of january 1 2007\t193\n",
      "increases in tax positions for the current year\t2\n",
      "increases in tax positions for prior years\t28\n",
      "decreases in tax positions of prior years\t-21 ( 21 )\n",
      "settlements\t-2 ( 2 )\n",
      "balance as of december 31 2007\t200\n",
      "included in the unrecognized tax benefits of $ 200 million as of december 31 , 2007 is $ 56 million of tax benefits that , if recognized , would reduce the company 2019s effective tax rate .\n",
      "the company recognizes interest and penalties related to unrecognized tax benefits in the provision for income taxes .\n",
      "as of december 31 , 2007 , the company has recorded a liability of approximately $ 36 million for interest and penalties .<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n",
      "\n",
      "Output Answer (Ground Truth):\n",
      "3.6%\n",
      "\n",
      "--- Example 3/5 (Original Index: 1957) ---\n",
      "Input Prompt (Formatted for Model):\n",
      "<bos><start_of_turn>user\n",
      "You are a helpful AI assistant that answers questions based on provided financial data.\n",
      "\n",
      "what is the percentage change in weighted average common shares outstanding for diluted computations from 2015 to 2016?\n",
      "benefits as an increase to earnings of $ 152 million ( $ 0.50 per share ) during the year ended december 31 , 2016 .\n",
      "additionally , we recognized additional income tax benefits as an increase to operating cash flows of $ 152 million during the year ended december 31 , 2016 .\n",
      "the new accounting standard did not impact any periods prior to january 1 , 2016 , as we applied the changes in the asu on a prospective basis .\n",
      "\t2016\t2015\t2014\n",
      "weighted average common shares outstanding for basic computations\t299.3\t310.3\t316.8\n",
      "weighted average dilutive effect of equity awards\t3.8\t4.4\t5.6\n",
      "weighted average common shares outstanding for dilutedcomputations\t303.1\t314.7\t322.4\n",
      "we compute basic and diluted earnings per common share by dividing net earnings by the respective weighted average number of common shares outstanding for the periods presented .\n",
      "our calculation of diluted earnings per common share also includes the dilutive effects for the assumed vesting of outstanding restricted stock units and exercise of outstanding stock options based on the treasury stock method .\n",
      "there were no anti-dilutive equity awards for the years ended december 31 , 2016 , 2015 and 2014 .<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n",
      "\n",
      "Output Answer (Ground Truth):\n",
      "-3.7%\n",
      "\n",
      "--- Example 4/5 (Original Index: 3142) ---\n",
      "Input Prompt (Formatted for Model):\n",
      "<bos><start_of_turn>user\n",
      "You are a helpful AI assistant that answers questions based on provided financial data.\n",
      "\n",
      "what percent does total depreciation & amortization expenses increase between 2006 and 2008?\n",
      "depreciation and amortization included in operating segment profit for the years ended december 31 , 2008 , 2007 and 2006 was as follows ( in millions ) : .\n",
      "\t2008\t2007\t2006\n",
      "americas\t$ 78.5\t$ 66.9\t$ 56.7\n",
      "europe\t57.0\t60.7\t46.5\n",
      "asia pacific\t25.6\t22.7\t18.7\n",
      "global operations and corporate functions\t114.0\t79.7\t75.5\n",
      "total\t$ 275.1\t$ 230.0\t$ 197.4\n",
      "15 .\n",
      "leases future minimum rental commitments under non- cancelable operating leases in effect as of december 31 , 2008 were $ 38.2 million for 2009 , $ 30.1 million for 2010 , $ 20.9 million for 2011 , $ 15.9 million for 2012 , $ 14.3 million for 2013 and $ 29.9 million thereafter .\n",
      "total rent expense for the years ended december 31 , 2008 , 2007 and 2006 aggregated $ 41.4 million , $ 37.1 million and $ 31.1 million , respectively .<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n",
      "\n",
      "Output Answer (Ground Truth):\n",
      "39.36%\n",
      "\n",
      "--- Example 5/5 (Original Index: 1195) ---\n",
      "Input Prompt (Formatted for Model):\n",
      "<bos><start_of_turn>user\n",
      "You are a helpful AI assistant that answers questions based on provided financial data.\n",
      "\n",
      "what was the average securitization rate of standby letters of credit as of december 2008 and 2007?\n",
      "notes to consolidated financial statements fifth third bancorp 81 vii held by the trust vii bear a fixed rate of interest of 8.875% ( 8.875 % ) until may 15 , 2058 .\n",
      "thereafter , the notes pay a floating rate at three-month libor plus 500 bp .\n",
      "the bancorp entered into an interest rate swap to convert $ 275 million of the fixed-rate debt into floating .\n",
      "( $ in millions )\t2008\t2007\n",
      "commitments to extend credit\t$ 49470\t49788\n",
      "letters of credit ( including standby letters of credit )\t8951\t8522\n",
      "forward contracts to sell mortgage loans\t3235\t1511\n",
      "noncancelable lease obligations\t937\t734\n",
      "purchase obligations\t81\t52\n",
      "capital expenditures\t68\t94\n",
      "commitments to extend credit are agreements to lend , typically having fixed expiration dates or other termination clauses that may require payment of a fee .\n",
      "since many of the commitments to extend credit may expire without being drawn upon , the total commitment amounts do not necessarily represent future cash flow requirements .\n",
      "the bancorp is exposed to credit risk in the event of nonperformance for the amount of the contract .<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n",
      "\n",
      "Output Answer (Ground Truth):\n",
      "68%\n",
      "--- End of Random Examples ---\n",
      "\n",
      "--- Analyzing split: validation ---\n",
      "Number of examples: 883\n",
      "                                                                                \n",
      "Input Token Statistics:\n",
      "  Total input tokens in split: 360746\n",
      "  Min input tokens per example: 146\n",
      "  Max input tokens per example: 1195\n",
      "  Mean input tokens per example: 408.5458663646659\n",
      "  Unique input tokens (diversity in this split): 4751\n",
      "\n",
      "Output Token Statistics:\n",
      "  Total output tokens in split: 4762\n",
      "  Min output tokens per example: 2\n",
      "  Max output tokens per example: 42\n",
      "  Mean output tokens per example: 5.392978482446206\n",
      "  Unique output tokens (diversity in this split): 41\n",
      "\n",
      "--- 5 Random Examples from 'validation' Split ---\n",
      "\n",
      "--- Example 1/5 (Original Index: 481) ---\n",
      "Input Prompt (Formatted for Model):\n",
      "<bos><start_of_turn>user\n",
      "You are a helpful AI assistant that answers questions based on provided financial data.\n",
      "\n",
      "what was the cost per car for the buyout of locomotives in 2012?\n",
      "we have adequate access to capital markets to meet any foreseeable cash requirements , and we have sufficient financial capacity to satisfy our current liabilities .\n",
      "cash flows millions 2014 2013 2012 .\n",
      "cash flowsmillions\t2014\t2013\t2012\n",
      "cash provided by operating activities\t$ 7385\t$ 6823\t$ 6161\n",
      "cash used in investing activities\t-4249 ( 4249 )\t-3405 ( 3405 )\t-3633 ( 3633 )\n",
      "cash used in financing activities\t-2982 ( 2982 )\t-3049 ( 3049 )\t-2682 ( 2682 )\n",
      "net change in cash and cashequivalents\t$ 154\t$ 369\t$ -154 ( 154 )\n",
      "operating activities higher net income in 2014 increased cash provided by operating activities compared to 2013 , despite higher income tax payments .\n",
      "2014 income tax payments were higher than 2013 primarily due to higher income , but also because we paid taxes previously deferred by bonus depreciation ( discussed below ) .\n",
      "higher net income in 2013 increased cash provided by operating activities compared to 2012 .<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n",
      "\n",
      "Output Answer (Ground Truth):\n",
      "454545\n",
      "\n",
      "--- Example 2/5 (Original Index: 641) ---\n",
      "Input Prompt (Formatted for Model):\n",
      "<bos><start_of_turn>user\n",
      "You are a helpful AI assistant that answers questions based on provided financial data.\n",
      "\n",
      "assuming a fmv of a share equal to 2000 , under the pre-december 31 , 2007 plan , approximately how many shares would each non-employee director receive annually?\n",
      "4 .\n",
      "stock options and other stock plans we have 100962 options outstanding under the 1993 stock option and retention stock plan of union pacific corporation ( 1993 plan ) .\n",
      "there are 7140 restricted shares outstanding under the 1992 restricted stock plan for non-employee directors of union pacific corporation .\n",
      "weighted-average assumptions\t2009\t2008\t2007\n",
      "risk-free interest rate\t1.9% ( 1.9 % )\t2.8% ( 2.8 % )\t4.9% ( 4.9 % )\n",
      "dividend yield\t2.3% ( 2.3 % )\t1.4% ( 1.4 % )\t1.4% ( 1.4 % )\n",
      "expected life ( years )\t5.1\t5.3\t4.7\n",
      "volatility\t31.3% ( 31.3 % )\t22.2% ( 22.2 % )\t20.9% ( 20.9 % )\n",
      "weighted-average grant-date fair value of options granted\t$ 11.33\t$ 13.35\t$ 11.19\n",
      ".<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n",
      "\n",
      "Output Answer (Ground Truth):\n",
      "90\n",
      "\n",
      "--- Example 3/5 (Original Index: 522) ---\n",
      "Input Prompt (Formatted for Model):\n",
      "<bos><start_of_turn>user\n",
      "You are a helpful AI assistant that answers questions based on provided financial data.\n",
      "\n",
      "what was the average total stock-based compensation expense from 2008 to 2010 in millions\n",
      "material impact on the service cost and interest cost components of net periodic benefit costs for a 1% ( 1 % ) change in the assumed health care trend rate .\n",
      "for most of the participants in the u.s .\n",
      "plan , aon 2019s liability for future plan cost increases for pre-65 and medical supplement plan coverage is limited to 5% ( 5 % ) per annum .\n",
      "years ended december 31\t2010\t2009\t2008\n",
      "rsus\t$ 138\t$ 124\t$ 132\n",
      "performance plans\t62\t60\t67\n",
      "stock options\t17\t21\t24\n",
      "employee stock purchase plans\t4\t4\t3\n",
      "total stock-based compensation expense\t221\t209\t226\n",
      "tax benefit\t75\t68\t82\n",
      "stock-based compensation expense net of tax\t$ 146\t$ 141\t$ 144\n",
      "during 2009 , the company converted its stock administration system to a new service provider .\n",
      "in connection with this conversion , a reconciliation of the methodologies and estimates utilized was performed , which resulted in a $ 12 million reduction of expense for the year ended december 31 , 2009 .\n",
      "stock awards stock awards , in the form of rsus , are granted to certain employees and consist of both performance-based and service-based rsus .<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n",
      "\n",
      "Output Answer (Ground Truth):\n",
      "218\n",
      "\n",
      "--- Example 4/5 (Original Index: 96) ---\n",
      "Input Prompt (Formatted for Model):\n",
      "<bos><start_of_turn>user\n",
      "You are a helpful AI assistant that answers questions based on provided financial data.\n",
      "\n",
      "what was the change in millions between 2012 and 2013 in currency hedges?\n",
      "notes to consolidated financial statements net investment hedges the firm seeks to reduce the impact of fluctuations in foreign exchange rates on its net investment in certain non- u.s .\n",
      "operations through the use of foreign currency forward contracts and foreign currency-denominated debt .\n",
      "for foreign currency forward contracts designated as hedges , the effectiveness of the hedge is assessed based on the overall changes in the fair value of the forward contracts ( i.e. , based on changes in forward rates ) .\n",
      "in millions\tyear ended december 2013\tyear ended december 2012\tyear ended december 2011\n",
      "currency hedges\t$ 150\t$ -233 ( 233 )\t$ 160\n",
      "foreign currency-denominated debt hedges\t470\t347\t-147 ( 147 )\n",
      "the gain/ ( loss ) related to ineffectiveness was not material for 2013 , 2012 or 2011 .\n",
      "the loss reclassified to earnings from accumulated other comprehensive income was not material for 2013 or 2012 , and was $ 186 million for 2011 .\n",
      "as of december 2013 and december 2012 , the firm had designated $ 1.97 billion and $ 2.77 billion , respectively , of foreign currency-denominated debt , included in 201cunsecured long-term borrowings 201d and 201cunsecured short- term borrowings , 201d as hedges of net investments in non- u.s .<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n",
      "\n",
      "Output Answer (Ground Truth):\n",
      "383\n",
      "\n",
      "--- Example 5/5 (Original Index: 496) ---\n",
      "Input Prompt (Formatted for Model):\n",
      "<bos><start_of_turn>user\n",
      "You are a helpful AI assistant that answers questions based on provided financial data.\n",
      "\n",
      "what is the increase observed in the first quarter dividend percentage concerning the total value , during 2018 and 2019?\n",
      "part ii item 5 .\n",
      "market for registrant 2019s common equity , related stockholder matters , and issuer purchases of equity securities our common stock is listed on the new york stock exchange under the symbol \"apd.\" as of 31 october 2019 , there were 5166 record holders of our common stock .\n",
      "cash dividends on the company 2019s common stock are paid quarterly .\n",
      "\t2019\t2018\n",
      "first quarter\t$ 1.10\t$ .95\n",
      "second quarter\t1.16\t1.10\n",
      "third quarter\t1.16\t1.10\n",
      "fourth quarter\t1.16\t1.10\n",
      "total\t$ 4.58\t$ 4.25\n",
      "purchases of equity securities by the issuer on 15 september 2011 , the board of directors authorized the repurchase of up to $ 1.0 billion of our outstanding common stock .\n",
      "this program does not have a stated expiration date .\n",
      "we repurchase shares pursuant to rules 10b5-1 and 10b-18 under the securities exchange act of 1934 , as amended , through repurchase agreements established with one or more brokers .<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n",
      "\n",
      "Output Answer (Ground Truth):\n",
      "1.66%\n",
      "--- End of Random Examples ---\n",
      "\n",
      "--- Analyzing split: test ---\n",
      "Number of examples: 1147\n",
      "                                                                                \n",
      "Input Token Statistics:\n",
      "  Total input tokens in split: 477970\n",
      "  Min input tokens per example: 127\n",
      "  Max input tokens per example: 865\n",
      "  Mean input tokens per example: 416.7131647776809\n",
      "  Unique input tokens (diversity in this split): 5204\n",
      "\n",
      "Output Token Statistics:\n",
      "  Total output tokens in split: 6257\n",
      "  Min output tokens per example: 2\n",
      "  Max output tokens per example: 37\n",
      "  Mean output tokens per example: 5.455100261551874\n",
      "  Unique output tokens (diversity in this split): 55\n",
      "\n",
      "--- 5 Random Examples from 'test' Split ---\n",
      "\n",
      "--- Example 1/5 (Original Index: 238) ---\n",
      "Input Prompt (Formatted for Model):\n",
      "<bos><start_of_turn>user\n",
      "You are a helpful AI assistant that answers questions based on provided financial data.\n",
      "\n",
      "what are the total operating expenses for 2016?\n",
      "delivered in 2015 compared to seven delivered in 2014 ) .\n",
      "the increases were partially offset by lower net sales of approximately $ 350 million for the c-130 program due to fewer aircraft deliveries ( 21 aircraft delivered in 2015 , compared to 24 delivered in 2014 ) , lower sustainment activities and aircraft contract mix ; approximately $ 200 million due to decreased volume and lower risk retirements on various programs ; approximately $ 195 million for the f-16 program due to fewer deliveries ( 11 aircraft delivered in 2015 , compared to 17 delivered in 2014 ) ; and approximately $ 190 million for the f-22 program as a result of decreased sustainment activities .\n",
      "aeronautics 2019 operating profit in 2015 increased $ 32 million , or 2% ( 2 % ) , compared to 2014 .\n",
      "\t2016\t2015\t2014\n",
      "net sales\t$ 6608\t$ 6770\t$ 7092\n",
      "operating profit\t1018\t1282\t1344\n",
      "operating margin\t15.4% ( 15.4 % )\t18.9% ( 18.9 % )\t19.0% ( 19.0 % )\n",
      "backlog atyear-end\t$ 14700\t$ 15500\t$ 13300\n",
      "2016 compared to 2015 mfc 2019s net sales in 2016 decreased $ 162 million , or 2% ( 2 % ) , compared to 2015 .\n",
      "the decrease was attributable to lower net sales of approximately $ 205 million for air and missile defense programs due to decreased volume ( primarily thaad ) ; and lower net sales of approximately $ 95 million due to lower volume on various programs .\n",
      "these decreases were partially offset by a $ 75 million increase for tactical missiles programs due to increased deliveries ( primarily hellfire ) ; and approximately $ 70 million for fire control programs due to increased volume ( sof clss ) .<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n",
      "\n",
      "Output Answer (Ground Truth):\n",
      "5590\n",
      "\n",
      "--- Example 2/5 (Original Index: 507) ---\n",
      "Input Prompt (Formatted for Model):\n",
      "<bos><start_of_turn>user\n",
      "You are a helpful AI assistant that answers questions based on provided financial data.\n",
      "\n",
      "what was the 2006 tax expense?\n",
      "notes to consolidated financial statements ( continued ) note 7 2014income taxes ( continued ) as of september 30 , 2006 , the company has state and foreign tax loss and state credit carryforwards , the tax effect of which is $ 55 million .\n",
      "certain of those carryforwards , the tax effect of which is $ 12 million , expire between 2016 and 2019 .\n",
      "a portion of these carryforwards was acquired from the company 2019s previous acquisitions , the utilization of which is subject to certain limitations imposed by the internal revenue code .\n",
      "\t2006\t2005 as restated ( 1 )\t2004 as restated ( 1 )\n",
      "computed expected tax\t$ 987\t$ 633\t$ 129\n",
      "state taxes net of federal effect\t86\t-19 ( 19 )\t-5 ( 5 )\n",
      "indefinitely invested earnings of foreign subsidiaries\t-224 ( 224 )\t-98 ( 98 )\t-31 ( 31 )\n",
      "nondeductible executive compensation\t11\t14\t12\n",
      "research and development credit net\t-12 ( 12 )\t-26 ( 26 )\t-5 ( 5 )\n",
      "other items\t-19 ( 19 )\t-24 ( 24 )\t4\n",
      "provision for income taxes\t$ 829\t$ 480\t$ 104\n",
      "effective tax rate\t29% ( 29 % )\t27% ( 27 % )\t28% ( 28 % )\n",
      "( 1 ) see note 2 , 201crestatement of consolidated financial statements . 201d the company 2019s income taxes payable has been reduced by the tax benefits from employee stock options .\n",
      "the company receives an income tax benefit calculated as the difference between the fair market value of the stock issued at the time of the exercise and the option price , tax effected .\n",
      "the net tax benefits from employee stock option transactions were $ 419 million , $ 428 million ( as restated ( 1 ) ) , and $ 83 million ( as restated ( 1 ) ) in 2006 , 2005 , and 2004 , respectively , and were reflected as an increase to common stock in the consolidated statements of shareholders 2019 equity. .<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n",
      "\n",
      "Output Answer (Ground Truth):\n",
      "$ 240.41\n",
      "\n",
      "--- Example 3/5 (Original Index: 917) ---\n",
      "Input Prompt (Formatted for Model):\n",
      "<bos><start_of_turn>user\n",
      "You are a helpful AI assistant that answers questions based on provided financial data.\n",
      "\n",
      "what percentage of restructuring cost comes from employee-related costs?\n",
      "with respect to our business operations , we are standardizing certain core business processes , primarily through our execution of the state street lean methodology , and driving automation of these business processes .\n",
      "we are currently creating a new technology platform , including transferring certain core software applications to a private cloud , and have expanded our use of service providers associated with components of our technology infrastructure and application maintenance and support .\n",
      "we expect the transfer of core software applications to a private cloud to occur primarily in 2013 and 2014 .\n",
      "( in millions )\temployee-related costs\treal estate consolidation\tinformation technology costs\ttotal\n",
      "2010\t$ 105\t$ 51\t\t$ 156\n",
      "2011\t85\t7\t$ 41\t133\n",
      "total\t$ 190\t$ 58\t$ 41\t$ 289\n",
      "the employee-related costs included costs related to severance , benefits and outplacement services .\n",
      "real estate consolidation costs resulted from actions taken to reduce our occupancy costs through consolidation of leases and properties .\n",
      "information technology costs included transition fees related to the above-described expansion of our use of service providers .<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n",
      "\n",
      "Output Answer (Ground Truth):\n",
      "65.7%\n",
      "\n",
      "--- Example 4/5 (Original Index: 728) ---\n",
      "Input Prompt (Formatted for Model):\n",
      "<bos><start_of_turn>user\n",
      "You are a helpful AI assistant that answers questions based on provided financial data.\n",
      "\n",
      "what is the yearly amortization rate for the trademarks?\n",
      "our intangible assets are amortized over their estimated useful lives of 1 to 13 years as shown in the table below .\n",
      "amortization is based on the pattern in which the economic benefits of the intangible asset will be consumed .\n",
      "weighted average useful life ( years ) .\n",
      "\tweighted average useful life ( years )\n",
      "purchased technology\t4\n",
      "localization\t1\n",
      "trademarks\t5\n",
      "customer contracts and relationships\t6\n",
      "other intangibles\t3\n",
      "software development costs capitalization of software development costs for software to be sold , leased , or otherwise marketed begins upon the establishment of technological feasibility , which is generally the completion of a working prototype that has been certified as having no critical bugs and is a release candidate .\n",
      "amortization begins once the software is ready for its intended use , generally based on the pattern in which the economic benefits will be consumed .\n",
      "to date , software development costs incurred between completion of a working prototype and general availability of the related product have not been material .<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n",
      "\n",
      "Output Answer (Ground Truth):\n",
      "20%\n",
      "\n",
      "--- Example 5/5 (Original Index: 103) ---\n",
      "Input Prompt (Formatted for Model):\n",
      "<bos><start_of_turn>user\n",
      "You are a helpful AI assistant that answers questions based on provided financial data.\n",
      "\n",
      "what is the percentage change in the total fair value of non-vested shares from 2009 to 2010?\n",
      "notes to consolidated financial statements 2014 ( continued ) the risk-free interest rate is based on the yield of a zero coupon united states treasury security with a maturity equal to the expected life of the option from the date of the grant .\n",
      "our assumption on expected volatility is based on our historical volatility .\n",
      "the dividend yield assumption is calculated using our average stock price over the preceding year and the annualized amount of our current quarterly dividend .\n",
      "\tshares\tweighted average grant-date fair value\n",
      "non-vested at may 31 2008\t518\t$ 39\n",
      "granted\t430\t43\n",
      "vested\t-159 ( 159 )\t39\n",
      "forfeited\t-27 ( 27 )\t41\n",
      "non-vested at may 31 2009\t762\t42\n",
      "granted\t420\t42\n",
      "vested\t-302 ( 302 )\t41\n",
      "forfeited\t-167 ( 167 )\t43\n",
      "non-vested at may 31 2010\t713\t42\n",
      "the weighted average grant-date fair value of share awards granted in the year ended may 31 , 2008 was $ 38 .\n",
      "the total fair value of share awards vested during the years ended may 31 , 2010 , 2009 and 2008 was $ 12.4 million , $ 6.2 million and $ 4.1 million , respectively .\n",
      "we recognized compensation expense for restricted stock of $ 12.1 million , $ 9.0 million , and $ 5.7 million in the years ended may 31 , 2010 , 2009 and 2008 .<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n",
      "\n",
      "Output Answer (Ground Truth):\n",
      "-4.1%\n",
      "--- End of Random Examples ---\n",
      "\n",
      "--- Overall Dataset Statistics (aggregated across analyzed splits) ---\n",
      "Total unique input token IDs (overall vocabulary diversity): 10871\n",
      "Total unique output token IDs (overall vocabulary diversity): 188\n",
      "Total unique tokens (input + output) in analyzed data: 10875\n",
      "Tokenizer's declared vocabulary size: 262144\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random # For random sampling\n",
    "\n",
    "# Ensure src module can be imported\n",
    "# ... (sys.path modification code if needed) ...\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from src.data import get_dataset_processor\n",
    "\n",
    "# Configuration\n",
    "MODEL_NAME = \"unsloth/gemma-3-1b-it\"\n",
    "MAX_SEQ_LENGTH = 1024\n",
    "DATASET_NAME = \"finqa\"\n",
    "DEFAULT_SYSTEM_PROMPT = \"You are a helpful AI assistant that answers questions based on provided financial data.\"\n",
    "\n",
    "def print_random_examples(dataset, tokenizer, num_examples_to_print=50, split_name=\"unknown\"):\n",
    "    \"\"\"\n",
    "    Prints a specified number of random examples from the dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset: The Hugging Face dataset object (output of processor.create_formatted_dataset).\n",
    "        tokenizer: The tokenizer instance.\n",
    "        num_examples_to_print: Number of random examples to print.\n",
    "        split_name: Name of the dataset split being processed.\n",
    "    \"\"\"\n",
    "    if not dataset or len(dataset) == 0:\n",
    "        print(f\"No examples to print from {split_name} split as it's empty.\")\n",
    "        return\n",
    "\n",
    "    actual_num_to_print = min(num_examples_to_print, len(dataset))\n",
    "    if actual_num_to_print == 0:\n",
    "        print(f\"No examples to print from {split_name} split.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n--- {actual_num_to_print} Random Examples from '{split_name}' Split ---\")\n",
    "\n",
    "    # Shuffle the dataset and select the desired number of examples\n",
    "    # .shuffle() returns a new shuffled dataset, .select() then picks a range\n",
    "    random_indices = random.sample(range(len(dataset)), actual_num_to_print)\n",
    "    sampled_examples = dataset.select(random_indices)\n",
    "\n",
    "    for i, example in enumerate(sampled_examples):\n",
    "        print(f\"\\n--- Example {i+1}/{actual_num_to_print} (Original Index: {random_indices[i]}) ---\")\n",
    "\n",
    "        # Input Prompt (formatted for model)\n",
    "        prompt_chat_format = example.get(\"prompt\")\n",
    "        if prompt_chat_format:\n",
    "            try:\n",
    "                # Convert the chat format (list of dicts) to a single string\n",
    "                # add_generation_prompt=True is important for how chat models expect input\n",
    "                input_prompt_string = tokenizer.apply_chat_template(\n",
    "                    prompt_chat_format,\n",
    "                    tokenize=False,\n",
    "                    add_generation_prompt=True\n",
    "                )\n",
    "                print(\"Input Prompt (Formatted for Model):\")\n",
    "                print(input_prompt_string)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not format input prompt: {e}\")\n",
    "                print(f\"Raw prompt structure: {prompt_chat_format}\")\n",
    "        else:\n",
    "            print(\"Input Prompt: [Not Available or Empty]\")\n",
    "\n",
    "        # Output Answer\n",
    "        output_answer = example.get(\"answer\")\n",
    "        if output_answer is not None: # Check for None, as empty string is a valid answer\n",
    "            print(\"\\nOutput Answer (Ground Truth):\")\n",
    "            print(output_answer)\n",
    "        else:\n",
    "            print(\"\\nOutput Answer: [Not Available]\")\n",
    "    print(\"--- End of Random Examples ---\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(f\"Loading tokenizer for: {MODEL_NAME}...\")\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            MODEL_NAME,\n",
    "            model_max_length=MAX_SEQ_LENGTH\n",
    "        )\n",
    "        print(\"Tokenizer loaded successfully using AutoTokenizer.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Could not load tokenizer for '{MODEL_NAME}': {e}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nLoading dataset processor for: {DATASET_NAME}...\")\n",
    "    try:\n",
    "        processor = get_dataset_processor(DATASET_NAME)\n",
    "        print(\"Dataset processor loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Could not load dataset processor for '{DATASET_NAME}': {e}\")\n",
    "        return\n",
    "\n",
    "    all_input_token_ids = []\n",
    "    all_output_token_ids = []\n",
    "    splits_to_analyze = [\"train\", \"validation\", \"test\"]\n",
    "\n",
    "    for split_name in splits_to_analyze:\n",
    "        print(f\"\\n--- Analyzing split: {split_name} ---\")\n",
    "        dataset_split = None # Initialize for current split\n",
    "        try:\n",
    "            dataset_split = processor.create_formatted_dataset(\n",
    "                system_prompt=DEFAULT_SYSTEM_PROMPT,\n",
    "                split=split_name\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load or process split '{split_name}': {e}\")\n",
    "            if DATASET_NAME == \"finqa\" and split_name == \"dev\":\n",
    "                 print(\"Note: For 'ibm-research/finqa', the validation split is named 'validation', not 'dev'.\")\n",
    "            continue # Skip to next split\n",
    "\n",
    "        if not dataset_split or len(dataset_split) == 0:\n",
    "            print(f\"No data found for split: {split_name}\")\n",
    "            continue\n",
    "\n",
    "        num_examples = len(dataset_split)\n",
    "        print(f\"Number of examples: {num_examples}\")\n",
    "\n",
    "        input_lengths = []\n",
    "        output_lengths = []\n",
    "        current_split_input_tokens = []\n",
    "        current_split_output_tokens = []\n",
    "\n",
    "        for i, example in enumerate(dataset_split):\n",
    "            if (i + 1) % 100 == 0 or i == num_examples - 1:\n",
    "                print(f\"Tokenizing example {i+1}/{num_examples} in {split_name}...\", end='\\r')\n",
    "\n",
    "            try:\n",
    "                input_string = tokenizer.apply_chat_template(\n",
    "                    example[\"prompt\"], tokenize=False, add_generation_prompt=True\n",
    "                )\n",
    "                input_ids = tokenizer(input_string, add_special_tokens=False).input_ids\n",
    "            except Exception as e_in:\n",
    "                print(f\"\\nError tokenizing input for example {i} in {split_name}: {e_in}\")\n",
    "                input_ids = []\n",
    "\n",
    "            try:\n",
    "                output_ids = tokenizer(example[\"answer\"], add_special_tokens=True).input_ids\n",
    "            except Exception as e_out:\n",
    "                print(f\"\\nError tokenizing output for example {i} in {split_name}: {e_out}\")\n",
    "                output_ids = []\n",
    "\n",
    "            input_lengths.append(len(input_ids))\n",
    "            output_lengths.append(len(output_ids))\n",
    "            current_split_input_tokens.extend(input_ids)\n",
    "            current_split_output_tokens.extend(output_ids)\n",
    "        \n",
    "        print(\" \" * 80, end='\\r')\n",
    "\n",
    "        all_input_token_ids.extend(current_split_input_tokens)\n",
    "        all_output_token_ids.extend(current_split_output_tokens)\n",
    "\n",
    "        # Statistics for the current split\n",
    "        if input_lengths:\n",
    "            print(\"\\nInput Token Statistics:\")\n",
    "            print(f\"  Total input tokens in split: {np.sum(input_lengths)}\")\n",
    "            print(f\"  Min input tokens per example: {np.min(input_lengths) if input_lengths else 'N/A'}\")\n",
    "            print(f\"  Max input tokens per example: {np.max(input_lengths) if input_lengths else 'N/A'}\")\n",
    "            print(f\"  Mean input tokens per example: {np.mean(input_lengths) if input_lengths else 'N/A'}\")\n",
    "            unique_input_tokens_split = len(set(current_split_input_tokens))\n",
    "            print(f\"  Unique input tokens (diversity in this split): {unique_input_tokens_split}\")\n",
    "        else:\n",
    "            print(\"No valid input tokens processed for this split.\")\n",
    "\n",
    "        if output_lengths:\n",
    "            print(\"\\nOutput Token Statistics:\")\n",
    "            print(f\"  Total output tokens in split: {np.sum(output_lengths)}\")\n",
    "            print(f\"  Min output tokens per example: {np.min(output_lengths) if output_lengths else 'N/A'}\")\n",
    "            print(f\"  Max output tokens per example: {np.max(output_lengths) if output_lengths else 'N/A'}\")\n",
    "            print(f\"  Mean output tokens per example: {np.mean(output_lengths) if output_lengths else 'N/A'}\")\n",
    "            unique_output_tokens_split = len(set(current_split_output_tokens))\n",
    "            print(f\"  Unique output tokens (diversity in this split): {unique_output_tokens_split}\")\n",
    "        else:\n",
    "            print(\"No valid output tokens processed for this split.\")\n",
    "\n",
    "        # Call the function to print random examples for the current split\n",
    "        # This is called *after* tokenization stats for the split are done.\n",
    "        if dataset_split and len(dataset_split) > 0 :\n",
    "            print_random_examples(dataset_split, tokenizer, num_examples_to_print=5, split_name=split_name) # printing 5 per split for brevity\n",
    "\n",
    "    print(\"\\n--- Overall Dataset Statistics (aggregated across analyzed splits) ---\")\n",
    "    if all_input_token_ids:\n",
    "        unique_input_tokens_overall = len(set(all_input_token_ids))\n",
    "        print(f\"Total unique input token IDs (overall vocabulary diversity): {unique_input_tokens_overall}\")\n",
    "    if all_output_token_ids:\n",
    "        unique_output_tokens_overall = len(set(all_output_token_ids))\n",
    "        print(f\"Total unique output token IDs (overall vocabulary diversity): {unique_output_tokens_overall}\")\n",
    "    combined_tokens = set(all_input_token_ids + all_output_token_ids)\n",
    "    if combined_tokens:\n",
    "        print(f\"Total unique tokens (input + output) in analyzed data: {len(combined_tokens)}\")\n",
    "    print(f\"Tokenizer's declared vocabulary size: {tokenizer.vocab_size}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
